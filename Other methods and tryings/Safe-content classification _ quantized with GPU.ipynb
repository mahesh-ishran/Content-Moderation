{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMdwJT4ScDMyGLV7Tzpi7SM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gIra5SdfkO7b","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1755156109731,"user_tz":-330,"elapsed":6217,"user":{"displayName":"Tecnologist Indian","userId":"15884987781070132694"}},"outputId":"1b9a7741-bb9e-48e2-c9d0-fad870e264b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers>=4.43.0 in /usr/local/lib/python3.11/dist-packages (4.55.2)\n","Requirement already satisfied: accelerate>=0.33.0 in /usr/local/lib/python3.11/dist-packages (1.10.0)\n","Requirement already satisfied: bitsandbytes>=0.43.0 in /usr/local/lib/python3.11/dist-packages (0.47.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Collecting torchvision\n","  Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.33.0) (5.9.5)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch) (75.2.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.43.0) (1.1.7)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (2025.8.3)\n","Downloading torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchvision-0.23.0\n"]}],"source":["!pip install \"transformers>=4.43.0\" \"accelerate>=0.33.0\" \"bitsandbytes>=0.43.0\" torch torchvision --upgrade"]},{"cell_type":"code","source":["!pip install --upgrade pip\n","!pip install --upgrade \"transformers>=4.43.0\" accelerate bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"vTHQnODYeNYw","executionInfo":{"status":"ok","timestamp":1755156388697,"user_tz":-330,"elapsed":9396,"user":{"displayName":"Tecnologist Indian","userId":"15884987781070132694"}},"outputId":"11f8db0a-2dce-441d-8d3c-e47128225705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n","Collecting pip\n","  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n","Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pip-25.2\n","Requirement already satisfied: transformers>=4.43.0 in /usr/local/lib/python3.11/dist-packages (4.55.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43.0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.43.0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.43.0) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.43.0) (1.1.7)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.8.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.43.0) (2025.8.3)\n"]}]},{"cell_type":"code","source":["import json\n","import re\n","from typing import Dict, Any, List, Optional\n","\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n","from threading import Thread"],"metadata":{"id":"3O5WT4H_k3t1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LABELS = [\n","    \"Explicit Nudity Detection\",\n","    \"Suggestive Content Detection\",\n","    \"Violence Detection\",\n","    \"Rude Gestures Detection\",\n","    \"Alcohol Content Detection\",\n","    \"Drugs Content Detection\",\n","    \"Tobacco Content Detection\",\n","    \"Hate Symbol Detection\",\n","]\n","\n","SYSTEM_PROMPT = \"\"\"You are a careful, literal content-safety classifier.\n","Return ONLY valid JSON that exactly matches the requested schema.\n","Do not add markdown fences, comments, or extra text.\"\"\"\n","\n","INSTRUCTION_TEMPLATE = \"\"\"Classify the INPUT text into the following labels.\n","\n","Labels (binary flags):\n","- Explicit Nudity Detection\n","- Suggestive Content Detection\n","- Violence Detection\n","- Rude Gestures Detection\n","- Alcohol Content Detection\n","- Drugs Content Detection\n","- Tobacco Content Detection\n","- Hate Symbol Detection\n","\n","Rules:\n","- Output MUST be a single JSON object.\n","- For each label, set \"flag\" to 0 (absent) or 1 (present).\n","- Provide a brief \"rationale\" (<= 20 words) explaining why or stating absence.\n","- Keep rationales neutral and professional.\n","- Do not include any keys not specified in the schema.\n","\n","Schema (example with all zeros):\n","{{\n","  \"Explicit Nudity Detection\":    {{\"flag\": 0, \"rationale\": \"No sexual body parts or explicit acts.\"}},\n","  \"Suggestive Content Detection\": {{\"flag\": 0, \"rationale\": \"No flirtatious or implicitly sexual wording.\"}},\n","  \"Violence Detection\":           {{\"flag\": 0, \"rationale\": \"No harm, threats, or injury described.\"}},\n","  \"Rude Gestures Detection\":      {{\"flag\": 0, \"rationale\": \"No obscene gestures mentioned.\"}},\n","  \"Alcohol Content Detection\":    {{\"flag\": 0, \"rationale\": \"No alcohol references.\"}},\n","  \"Drugs Content Detection\":      {{\"flag\": 0, \"rationale\": \"No illicit or prescription drug misuse.\"}},\n","  \"Tobacco Content Detection\":    {{\"flag\": 0, \"rationale\": \"No tobacco references.\"}},\n","  \"Hate Symbol Detection\":        {{\"flag\": 0, \"rationale\": \"No hate symbols or extremist insignia.\"}}\n","}}\n","\n","INPUT:\n","\\\"\\\"\\\"{text}\\\"\\\"\\\"\n","\"\"\""],"metadata":{"id":"jDRboDUIUFFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----------------------------\n","# Config\n","# ----------------------------\n","MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct\"\n","LOAD_4BIT = True              # set to False if you want full precision (needs more VRAM/RAM)\n","MAX_NEW_TOKENS = 512\n","TEMPERATURE = 0.0             # deterministic for classification\n","TOP_P = 0.9\n","DEVICE_MAP = \"auto\"           # let Accelerate place layers\n","TORCH_DTYPE = torch.bfloat16 if torch.cuda.is_available() else torch.float32"],"metadata":{"id":"ED8R8A3sT_eh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hf_token = '............'\n","def load_model():\n","  kwargs = dict(\n","    device_map=DEVICE_MAP,\n","    torch_dtype=TORCH_DTYPE,\n","  )\n","  if LOAD_4BIT and torch.cuda.is_available():\n","    kwargs.update(\n","      dict(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=TORCH_DTYPE,\n","      )\n","    )\n","  model = AutoModelForCausalLM.from_pretrained(MODEL_ID, trust_remote_code=False, **kwargs,token=hf_token)\n","  tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True,token=hf_token)\n","  return model, tokenizer"],"metadata":{"id":"mPfT1wnMUgKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_prompt(text: str, tokenizer: AutoTokenizer) -> Dict[str, List[Dict[str, str]]]:\n","  # Use the chat template expected by *-Instruct models\n","  messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},{\"role\": \"user\", \"content\": INSTRUCTION_TEMPLATE.format(text=text)},]\n","  prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","  return prompt"],"metadata":{"id":"LHKfycq3VFJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_json(model, tokenizer, prompt: str) -> str:\n","  inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","  streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","  gen_kwargs = dict(\n","    **inputs,\n","    streamer=streamer,\n","    max_new_tokens=MAX_NEW_TOKENS,\n","    temperature=TEMPERATURE,\n","    top_p=TOP_P,\n","    do_sample=(TEMPERATURE > 0.0),\n","    eos_token_id=tokenizer.eos_token_id,)\n","  thread = Thread(target=model.generate, kwargs=gen_kwargs)\n","  thread.start()\n","  chunks = []\n","  for part in streamer:\n","    chunks.append(part)\n","  thread.join()\n","  return \"\".join(chunks).strip()"],"metadata":{"id":"Gz5v952Ta2fa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_json(text: str) -> Optional[str]:\n","  \"\"\"\n","  Try to extract a JSON object from the model text (in case it strays).\n","  Prefer the largest outermost {...}.\n","  \"\"\"\n","  # If it already looks like clean JSON, use it\n","  if text.startswith(\"{\") and text.endswith(\"}\"):\n","    return text\n","  # Otherwise, try to find the first and last curly braces\n","  match = re.search(r\"\\{.*\\}\", text, flags=re.S)\n","  return match.group(0) if match else None"],"metadata":{"id":"GSIHgNUra8Eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate_output(obj: Any) -> Dict[str, Any]:\n","  \"\"\"\n","  Ensure all labels exist and each has {\"flag\": 0|1, \"rationale\": str}.\n","  Fill missing labels with zeros.\n","  \"\"\"\n","  result = {}\n","  for label in LABELS:\n","    entry = obj.get(label, None) if isinstance(obj, dict) else None\n","    if not isinstance(entry, dict):\n","      result[label] = {\"flag\": 0, \"rationale\": \"Not mentioned.\"}\n","      continue\n","    flag = entry.get(\"flag\", 0)\n","    flag = 1 if str(flag).strip() == \"1\" else 0\n","    rationale = entry.get(\"rationale\", \"No rationale provided.\")\n","    if not isinstance(rationale, str):\n","      rationale = str(rationale)\n","    result[label] = {\"flag\": flag, \"rationale\": rationale[:160]}\n","  return result"],"metadata":{"id":"X9M7AJSebCQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classify_text(text: str, model=None, tokenizer=None, retry_on_parse_error: bool = True) -> Dict[str, Any]:\n","  owned = False\n","  if model is None or tokenizer is None:\n","    model, tokenizer = load_model()\n","    owned = True\n","  try:\n","    prompt = build_prompt(text, tokenizer)\n","    raw = generate_json(model, tokenizer, prompt)\n","    jtxt = extract_json(raw)\n","    if jtxt is None:\n","        if retry_on_parse_error:\n","            # One gentle retry with a stricter reminder\n","            retry_prompt = build_prompt(\n","                text + \"\\n\\nREMINDER: Output ONLY valid JSON object. No backticks. No extra text.\",\n","                tokenizer\n","            )\n","            raw = generate_json(model, tokenizer, retry_prompt)\n","            jtxt = extract_json(raw)\n","    if jtxt is None:\n","        raise ValueError(f\"Model did not return JSON. Raw output:\\n{raw}\")\n","\n","    parsed = json.loads(jtxt)\n","    return {\n","        \"raw_text\": text,\n","        \"model_output\": validate_output(parsed),\n","    }\n","  finally:\n","    # If you want to free VRAM/RAM when model was created inside this call:\n","    if owned:\n","      try:\n","        del model, tokenizer\n","        if torch.cuda.is_available():\n","          torch.cuda.empty_cache()\n","      except Exception:\n","        pass"],"metadata":{"id":"tD3WxOqbbQkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","\n","# ----------------------------\n","# Example usage\n","# ----------------------------\n","if __name__ == \"__main__\":\n","  sample_texts = [\n","    \"They were clinking beer bottles at the bar after work.\",\n","    \"The poster shows a skull with a swastika armband.\",\n","    \"He threatened to punch me if I didn’t pay.\",\n","    \"She winked and said the dress is 'barely decent'.\",\n","    \"The ad shows a man flipping the bird.\",\n","    \"He rolled a joint and lit it.\",\n","    \"Smoking a pack a day is terrible for your lungs.\",\n","    \"The content describes explicit sexual acts and exposed genitals.\",\n","  ]\n","\n","  model, tokenizer = load_model()\n","  for t in sample_texts:\n","    res = classify_text(t, model, tokenizer)\n","    print(json.dumps(res, indent=2, ensure_ascii=False))\n"],"metadata":{"id":"zeURqxazk0P3","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1755156398135,"user_tz":-330,"elapsed":272,"user":{"displayName":"Tecnologist Indian","userId":"15884987781070132694"}},"outputId":"187c22f4-f394-4711-bc34-e7b949f34330"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/usr/local/lib/python3.11/dist-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/usr/local/lib/python3.11/dist-packages/transformers/__init__.py'>!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find {attr} in {transformers_module}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Could not find LlamaForCausalLM in <module 'transformers' from '/usr/local/lib/python3.11/dist-packages/transformers/__init__.py'>!","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2106349412.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   ]\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-60260817.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       )\n\u001b[1;32m     15\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m             )\n\u001b[1;32m    596\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0msupported_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupported_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_attr_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;31m# Maybe there was several model types associated with this config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transformers.models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattribute_from_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find {attr} neither in {module} nor in {transformers_module}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find {attr} in {transformers_module}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/usr/local/lib/python3.11/dist-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/usr/local/lib/python3.11/dist-packages/transformers/__init__.py'>!"]}]}]}